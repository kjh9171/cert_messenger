import requests
from bs4 import BeautifulSoup
import telegram
import asyncio
import schedule
import time
from datetime import datetime, timedelta, timezone
import sys
import os
import urllib3
import html
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# SSL ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ì„¤ì •
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- ì„¤ì • ì •ë³´ ---
TELEGRAM_TOKEN = '8458654696:AAFbyTsyeGw2f7OO9sYm3wlQiS5NY72F3J0'
CHAT_ID = '7220628007'

URLS = {
    "yonhap": "https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&sid1=001&sid2=140&oid=001&isYeonhapFlash=Y",
    "cisa_kev": "https://www.cvedetails.com/cisa-known-exploited-vulnerabilities/kev-1.html",
    "boannews": "https://www.boannews.com/media/list.asp",
    "clien_park": "https://www.clien.net/service/group/community",
    "ddanzi": "https://www.ddanzi.com/free",
    "mbc": "https://imnews.imbc.com/replay/2026/nwdesk/",
    "naver_stock": "https://stock.naver.com/",
    "ddanzi_news": "https://www.ddanzi.com/ddanziNews"
}

last_sent_titles = set()

def get_kst_now():
    return datetime.now(timezone(timedelta(hours=9)))

def capture_article_image(url, filename):
    """íŠ¹ì • ì˜ì—­(ë³¸ë¬¸)ë§Œ íƒ€ê²ŸíŒ…í•˜ì—¬ ìº¡ì²˜í•˜ëŠ” ìµœì í™”ëœ í•¨ìˆ˜"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    # ëª¨ë°”ì¼ ë·°í¬íŠ¸ì™€ ìœ ì‚¬í•˜ê²Œ ì„¤ì •í•˜ì—¬ ê°€ë…ì„± ì¦ëŒ€
    chrome_options.add_argument("--window-size=800,1200")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1")

    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get(url)
        
        # ë”´ì§€ì¼ë³´/ë‰´ìŠ¤ íŠ¹í™” ìº¡ì²˜ ì˜ì—­ ì§€ì • (ID: 'content' ë˜ëŠ” í´ë˜ìŠ¤ ê¸°ë°˜)
        wait = WebDriverWait(driver, 10)
        
        # ë”´ì§€ì¼ë³´ ë³¸ë¬¸ ì˜ì—­ì´ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        target_element = None
        if "ddanzi.com" in url:
            try:
                # ê²Œì‹œíŒ ë³¸ë¬¸ ì˜ì—­ ì„ íƒ ì‹œë„
                target_element = wait.until(EC.presence_of_element_located((By.ID, "content")))
            except:
                # ë‰´ìŠ¤ ì˜ì—­ ë“± ë‹¤ë¥¸ ë ˆì´ì•„ì›ƒì¼ ê²½ìš°
                target_element = driver.find_element(By.TAG_NAME, "body")
        
        if target_element:
            # íŠ¹ì • ìš”ì†Œë§Œ ìŠ¤í¬ë¦°ìƒ· ì°ê¸°
            target_element.screenshot(filename)
        else:
            driver.save_screenshot(filename)
            
        return filename
    except Exception as e:
        print(f"ìº¡ì²˜ ì‹¤íŒ¨ ({url}): {e}")
        return None
    finally:
        if driver:
            driver.quit()

def fetch_data():
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"}
    all_content = []

    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    
    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
    except Exception as e:
        print(f"Selenium ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    # [ì¤‘ëµ: ì—°í•©, CVE, ë³´ì•ˆë‰´ìŠ¤, í´ë¦¬ì•™ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€]
    # (ê¸°ì¡´ ì½”ë“œì˜ 1~4ë²ˆ ì„¹ì…˜ ìœ ì§€)

    # 5. ë”´ì§€ì¼ë³´ ììœ ê²Œì‹œíŒ (ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ê°€)
    try:
        res = requests.get(URLS["ddanzi"], headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        items = soup.select('table.fz_change tbody tr')
        count = 0
        for item in items:
            if count >= 5: break
            no_tag = item.select_one('.no')
            if not no_tag or not no_tag.get_text().strip().isdigit(): continue

            title_tag = item.select_one('.title a.link')
            if title_tag:
                title = title_tag.get_text().strip()
                link = title_tag['href']
                if not link.startswith('http'): link = "https://www.ddanzi.com" + link
                
                # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ (ì„ íƒ ì‚¬í•­)
                # ê²Œì‹œíŒ ëª©ë¡ì—ì„œëŠ” ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ì œëª©ì— ì§‘ì¤‘
                
                all_content.append({
                    "source": "ë”´ì§€ê²Œì‹œíŒ", 
                    "title": title, 
                    "link": link,
                    "author": item.select_one('.author').get_text().strip() if item.select_one('.author') else "ìµëª…",
                    "hits": item.select_one('.readNum').get_text().strip() if item.select_one('.readNum') else "0"
                })
                count += 1
    except Exception as e: print(f"ë”´ì§€ê²Œì‹œíŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # [ì¤‘ëµ: MBC, ë„¤ì´ë²„ ì¦ê¶Œ ìœ ì§€]
    
    # 8. ë”´ì§€ë‰´ìŠ¤ (ë³¸ë¬¸ ìš”ì•½ ë¡œì§ ì¶”ê°€)
    if driver:
        try:
            driver.get(URLS["ddanzi_news"])
            time.sleep(3)
            links = driver.find_elements(By.CSS_SELECTOR, 'a[href*="/ddanziNews/"]')
            seen_links = set()
            count = 0
            for link_el in links:
                if count >= 3: break
                title = link_el.text.strip()
                link = link_el.get_attribute('href')
                if title and link and link not in seen_links:
                    all_content.append({
                        "source": "ë”´ì§€ë‰´ìŠ¤",
                        "title": title,
                        "link": link,
                        "category": "ì‹œì‚¬/ì´ìŠˆ"
                    })
                    seen_links.add(link)
                    count += 1
        except Exception as e: print(f"ë”´ì§€ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    if driver: driver.quit()
    return all_content

async def send_briefing(is_test=False):
    global last_sent_titles
    now = get_kst_now()
    now_str = now.strftime('%Y-%m-%d %H:%M')
    
    data = fetch_data()
    if is_test:
        new_items = data[:5]
    else:
        new_items = [d for d in data if d['link'] not in last_sent_titles]

    if not new_items: return

    bot = telegram.Bot(token=TELEGRAM_TOKEN)

    for item in new_items:
        icons = {"ì—°í•©ë‰´ìŠ¤ ì†ë³´": "ğŸ—ï¸", "cve ì·¨ì•½ì  ì•Œë¦¼": "ğŸš¨", "ë³´ì•ˆë‰´ìŠ¤": "ğŸ›¡ï¸", "í´ë¦¬ì•™ ëª¨ë‘ì˜ ê³µì›": "ğŸ‘¥", "ë”´ì§€ê²Œì‹œíŒ": "ğŸ”¥", "MBC ë‰´ìŠ¤": "ğŸ“º", "ë„¤ì´ë²„ ì¦ê¶Œ AI": "ğŸ“ˆ", "ë”´ì§€ë‰´ìŠ¤": "ğŸ“°"}
        icon = icons.get(item['source'], "ğŸ“¢")

        safe_title = html.escape(item['title'])
        safe_source = html.escape(item['source'])

        report = f"<b>{icon} {safe_source}</b>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        report += f"ğŸ“Œ <b>{safe_title}</b>\n\n"
        
        if 'author' in item: report += f"ğŸ‘¤ <b>ì‘ì„±ì:</b> {html.escape(item['author'])}\n"
        if 'hits' in item: report += f"ğŸ‘€ <b>ì¡°íšŒìˆ˜:</b> {item['hits']}\n"
        
        report += f"ğŸ”— <a href='{item['link']}'>ì›ë¬¸ ë§í¬ ë³´ê¸°</a>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        report += f"â° <i>ìˆ˜ì§‘ì¼ì‹œ: {now_str}</i>"

        temp_img = f"shot_{int(time.time())}.png"

        try:
            # ê°œì„ ëœ ìº¡ì²˜ í•¨ìˆ˜ í˜¸ì¶œ
            img_path = capture_article_image(item['link'], temp_img)

            if img_path and os.path.exists(img_path):
                with open(img_path, 'rb') as photo:
                    await bot.send_photo(chat_id=CHAT_ID, photo=photo, caption=report, parse_mode='HTML')
                os.remove(img_path)
            else:
                await bot.send_message(chat_id=CHAT_ID, text=report, parse_mode='HTML')
            
            last_sent_titles.add(item['link'])
            await asyncio.sleep(1)
        except Exception as e:
            print(f"ì „ì†¡ ì˜¤ë¥˜: {e}")

    if len(last_sent_titles) > 2000:
        last_sent_titles = set(list(last_sent_titles)[-2000:])

def job_wrapper(is_test=False):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(send_briefing(is_test=is_test))
    finally:
        loop.close()

if __name__ == "__main__":
    job_wrapper(is_test=True) 
    schedule.every().hour.at(":00").do(job_wrapper)
    while True:
        schedule.run_pending()
        time.sleep(1)