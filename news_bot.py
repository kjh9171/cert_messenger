import requests
from bs4 import BeautifulSoup
import telegram
import asyncio
import schedule
import time
from datetime import datetime, timedelta, timezone
import sys # ì‹œìŠ¤í…œ ê´€ë ¨ ëª¨ë“ˆ
import os # íŒŒì¼ ê²½ë¡œ ë° í™˜ê²½ ë³€ìˆ˜ ê´€ë ¨ ëª¨ë“ˆ
import urllib3 # HTTP ìš”ì²­ ì‹œ ê²½ê³  ë¬´ì‹œ ë“±ì„ ìœ„í•œ ëª¨ë“ˆ
import html # HTML íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager

# SSL ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ ì„¤ì •
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- ì„¤ì • ì •ë³´ ---
TELEGRAM_TOKEN = '8458654696:AAFbyTsyeGw2f7OO9sYm3wlQiS5NY72F3J0'
CHAT_ID = '7220628007'

# ìˆ˜ì§‘ ëŒ€ìƒ URL (KISA ëŒ€ì‹  CVE ì·¨ì•½ì  ì‚¬ì´íŠ¸ ì¶”ê°€)
URLS = {
    "yonhap": "https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&sid1=001&sid2=140&oid=001&isYeonhapFlash=Y",
    "cisa_kev": "https://www.cvedetails.com/cisa-known-exploited-vulnerabilities/kev-1.html",
    "boannews": "https://www.boannews.com/media/list.asp",
    "clien_park": "https://www.clien.net/service/group/community"
}

last_sent_titles = set()

def get_kst_now():
    """UTC ê¸°ë°˜ í™˜ê²½ì—ì„œë„ ì •í™•í•œ í•œêµ­ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(timezone(timedelta(hours=9)))

def capture_article_image(url, filename):
    """Seleniumì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ í˜ì´ì§€ì˜ ì£¼ìš” ë¶€ë¶„ì„ ìº¡ì²˜í•©ë‹ˆë‹¤."""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1280,1024")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")

    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.set_page_load_timeout(30)
        driver.get(url)
        time.sleep(5) 
        
        driver.save_screenshot(filename)
        return filename
    except Exception as e:
        print(f"ìº¡ì²˜ ì‹¤íŒ¨ ({url}): {e}")
        return None
    finally:
        if driver:
            driver.quit()

def fetch_data():
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"}
    all_content = []

    # 1. ì—°í•©ë‰´ìŠ¤ ì†ë³´
    try:
        res = requests.get(URLS["yonhap"], headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        for item in soup.select('.list_body li')[:5]:
            title_tag = item.select_one('a')
            if title_tag:
                title = title_tag.get_text().strip()
                link = title_tag['href']
                if not link.startswith('http'): link = "https://news.naver.com" + link
                all_content.append({"source": "ì—°í•©ë‰´ìŠ¤ ì†ë³´", "title": title, "link": link})
    except Exception as e: print(f"ì—°í•©ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # 2. CISA Known Exploited Vulnerabilities (CVE ì—…ë°ì´íŠ¸)
    try:
        res = requests.get(URLS["cisa_kev"], headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        # í…Œì´ë¸” ë‚´ì˜ CVE IDì™€ ì œëª© ì¶”ì¶œ
        rows = soup.select('table.searchresults tr')[1:6] # í—¤ë” ì œì™¸ ìƒìœ„ 5ê°œ
        for row in rows:
            cols = row.find_all('td')
            if len(cols) > 2:
                cve_id = cols[1].get_text().strip()
                vendor_product = cols[2].get_text().strip()
                vulnerability_name = cols[3].get_text().strip()
                title = f"[{cve_id}] {vendor_product} - {vulnerability_name}"
                # ìƒì„¸ ì •ë³´ ë§í¬ ìƒì„±
                link_tag = cols[1].find('a')
                link = "https://www.cvedetails.com" + link_tag['href'] if link_tag else URLS["cisa_kev"]
                all_content.append({"source": "cve ì·¨ì•½ì  ì•Œë¦¼", "title": title, "link": link})
    except Exception as e: print(f"CVE í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # 3. ë³´ì•ˆë‰´ìŠ¤
    try:
        res = requests.get(URLS["boannews"], headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        for item in soup.select('.news_list')[:5]:
            title_tag = item.select_one('.news_txt')
            link_tag = item.select_one('a')
            if title_tag and link_tag:
                title = title_tag.get_text().strip()
                link = "https://www.boannews.com" + link_tag['href']
                all_content.append({"source": "ë³´ì•ˆë‰´ìŠ¤", "title": title, "link": link})
    except Exception as e: print(f"ë³´ì•ˆë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # 4. í´ë¦¬ì•™ ëª¨ë‘ì˜ ê³µì› í¬ë¡¤ë§
    try:
        # í´ë¦¬ì•™ 'ëª¨ë‘ì˜ ê³µì›' í˜ì´ì§€ ìš”ì²­
        res = requests.get(URLS["clien_park"], headers=headers, timeout=10)
        # ì‘ë‹µ ë°›ì€ HTML ì†ŒìŠ¤ë¥¼ íŒŒì‹± ê°€ëŠ¥í•œ ê°ì²´ë¡œ ë³€í™˜
        soup = BeautifulSoup(res.text, 'html.parser')
        # ê²Œì‹œê¸€ ë¦¬ìŠ¤íŠ¸ í•­ëª©ë“¤ì„ ì„ íƒ
        items = soup.select('.list_content .list_item')
        count = 0
        for item in items:
            if count >= 5: break # ìƒìœ„ 5ê°œ í•­ëª©ë§Œ ìˆ˜ì§‘
            # ì œëª©ê³¼ ë§í¬ê°€ í¬í•¨ëœ ìš”ì†Œ ì„ íƒ
            title_tag = item.select_one('.list_title .list_subject')
            if title_tag:
                # ê²Œì‹œê¸€ ì œëª© ì¶”ì¶œ
                title = title_tag.get_text().strip()
                # ê²Œì‹œê¸€ ìƒì„¸ ë§í¬ ìƒì„±
                link = "https://www.clien.net" + title_tag['href']
                
                # [ê³ ë„í™”] ì‘ì„±ì ì •ë³´ ì¶”ì¶œ ì‹œë„
                author_tag = item.select_one('.nickname')
                author = author_tag.get_text().strip() if author_tag else "ìµëª…"
                
                # [ê³ ë„í™”] ì¡°íšŒìˆ˜ ì •ë³´ ì¶”ì¶œ ì‹œë„
                hit_tag = item.select_one('.hit')
                hits = hit_tag.get_text().strip() if hit_tag else "0"
                
                # ìˆ˜ì§‘ëœ ì •ë³´ë¥¼ ìƒì„¸ ë°ì´í„°ì™€ í•¨ê»˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                all_content.append({
                    "source": "í´ë¦¬ì•™ ëª¨ë‘ì˜ ê³µì›", 
                    "title": title, 
                    "link": link,
                    "author": author,
                    "hits": hits
                })
                count += 1
    except Exception as e: print(f"í´ë¦¬ì•™ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    return all_content

async def send_briefing():
    """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¸Œë¦¬í•‘ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•˜ì—¬ í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."""
    global last_sent_titles
    # í˜„ì¬ í•œêµ­ ì‹œê°„ ì •ë³´ íšë“
    now = get_kst_now()
    # ì „ì†¡ ì‹œê° ë¬¸ìì—´ ìƒì„±
    now_str = now.strftime('%Y-%m-%d %H:%M')
    
    # ê° ì‚¬ì´íŠ¸ë¡œë¶€í„° ìµœì‹  ë°ì´í„° í˜¸ì¶œ
    data = fetch_data()
    # [ê³ ë„í™”] ë§í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì—¬ë¶€ íŒë‹¨ (ì œëª© ë³€ê²½ ì‹œ ì¤‘ë³µ ì „ì†¡ ë°©ì§€)
    new_items = [d for d in data if d['link'] not in last_sent_titles]

    if not new_items:
        # ìƒˆë¡œìš´ í•­ëª©ì´ ì—†ìœ¼ë©´ ë¡œê·¸ ë‚¨ê¸°ê³  ì¢…ë£Œ
        print(f"[{now_str}] ì—…ë°ì´íŠ¸ëœ ìƒˆë¡œìš´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í…”ë ˆê·¸ë¨ ë´‡ ê°ì²´ ìƒì„±
    bot = telegram.Bot(token=TELEGRAM_TOKEN)

    for item in new_items:
        # [ê³ ë„í™”] ì†ŒìŠ¤ë³„ ì´ëª¨ì§€ ì„¤ì •ìœ¼ë¡œ ì‹œì¸ì„± ê°•í™”
        icons = {"ì—°í•©ë‰´ìŠ¤ ì†ë³´": "ğŸ—ï¸", "cve ì·¨ì•½ì  ì•Œë¦¼": "ğŸš¨", "ë³´ì•ˆë‰´ìŠ¤": "ğŸ›¡ï¸", "í´ë¦¬ì•™ ëª¨ë‘ì˜ ê³µì›": "ğŸ‘¥"}
        icon = icons.get(item['source'], "ğŸ“¢")

        # [ê³ ë„í™”] HTML íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ (íƒœê·¸ ì¶©ëŒ ë°©ì§€)
        safe_title = html.escape(item['title'])
        safe_source = html.escape(item['source'])

        # [ê³ ë„í™”] í”„ë¦¬ë¯¸ì—„ ìŠ¤íƒ€ì¼ì˜ HTML ë©”ì‹œì§€ êµ¬ì„±
        report = f"<b>{icon} {safe_source}</b>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        report += f"ğŸ“Œ <b>{safe_title}</b>\n\n"
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° (í´ë¦¬ì•™ ë“±) ì¶œë ¥ ë‚´ìš© ë³´ê°•
        if 'author' in item:
            report += f"ğŸ‘¤ <b>ì‘ì„±ì:</b> {html.escape(item['author'])}\n"
        if 'hits' in item:
            report += f"ğŸ‘€ <b>ì¡°íšŒìˆ˜:</b> {item['hits']}\n"
            
        # ì›ë¬¸ ë§í¬ë¥¼ ë²„íŠ¼ í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¡œ ì œê³µ
        report += f"ğŸ”— <a href='{item['link']}'>ì›ë¬¸ ë§í¬ ë³´ê¸°</a>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        report += f"â° <i>ìˆ˜ì§‘ì¼ì‹œ: {now_str}</i>"

        # ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜ë¥¼ ìœ„í•œ ì„ì‹œ íŒŒì¼ëª… ìƒì„±
        temp_img = f"shot_{int(time.time())}_{new_items.index(item)}.png"

        try:
            # ê¸°ì‚¬ í˜ì´ì§€ ìº¡ì²˜ ì‹œë„
            img_path = capture_article_image(item['link'], temp_img)

            if img_path and os.path.exists(img_path):
                # ì‚¬ì§„ì´ ì„±ê³µì ìœ¼ë¡œ ìº¡ì²˜ëœ ê²½ìš° ìº¡ì…˜ê³¼ í•¨ê»˜ ì „ì†¡ (HTML íŒŒì‹± ëª¨ë“œ ì ìš©)
                with open(img_path, 'rb') as photo:
                    await bot.send_photo(chat_id=CHAT_ID, photo=photo, caption=report, parse_mode='HTML')
                # ì „ì†¡ í›„ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                os.remove(img_path)
            else:
                # ìº¡ì²˜ ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë§Œ ì „ì†¡ (HTML íŒŒì‹± ëª¨ë“œ ì ìš©)
                await bot.send_message(chat_id=CHAT_ID, text=report, parse_mode='HTML')
            
            # [ê³ ë„í™”] ì „ì†¡ ì™„ë£Œëœ í•­ëª©ì˜ ë§í¬ë¥¼ ì €ì¥í•˜ì—¬ ì¤‘ë³µ ì „ì†¡ ë°©ì§€
            last_sent_titles.add(item['link'])
            # ì—°ì† ì „ì†¡ ì‹œ í…”ë ˆê·¸ë¨ ì†ë„ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°
            await asyncio.sleep(1)
        except Exception as e:
            print(f"ì „ì†¡ ì˜¤ë¥˜: {e}")

    # ê¸°ë¡ì´ ë„ˆë¬´ ë§ì•„ì§€ë©´ ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ ìµœê·¼ 2000ê°œë§Œ ìœ ì§€
    if len(last_sent_titles) > 2000:
        last_sent_titles = set(list(last_sent_titles)[-2000:])
    print(f"[{now_str}] ëª¨ë“  ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ.")

def job_wrapper():
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(send_briefing())
    finally:
        loop.close()

if __name__ == "__main__":
    print("ì·¨ì•½ì  ë° ë‰´ìŠ¤ í†µí•© ë¸Œë¦¬í•‘ ì‹œìŠ¤í…œ ê°€ë™ ì‹œì‘...")
    job_wrapper() 
    schedule.every().hour.at(":00").do(job_wrapper)
    while True:
        schedule.run_pending()
        time.sleep(1)