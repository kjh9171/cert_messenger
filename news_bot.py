import requests
from bs4 import BeautifulSoup
import telegram
import asyncio
import schedule
import time
from datetime import datetime, timedelta, timezone
import sys
import os
import urllib3
import html
import re  # ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•œ ì •ê·œí‘œí˜„ì‹ ì¶”ê°€
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- ì„¤ì • ì •ë³´ ---
TELEGRAM_TOKEN = '8458654696:AAFbyTsyeGw2f7OO9sYm3wlQiS5NY72F3J0'
CHAT_ID = '7220628007'

URLS = {
    "yonhap": "https://news.naver.com/main/list.naver?mode=LPOD&mid=sec&sid1=001&sid2=140&oid=001&isYeonhapFlash=Y",
    "cisa_kev": "https://www.cvedetails.com/cisa-known-exploited-vulnerabilities/kev-1.html",
    "boannews": "https://www.boannews.com/media/list.asp",
    "clien_park": "https://www.clien.net/service/group/community",
    "ddanzi": "https://www.ddanzi.com/free",
    "mbc": "https://imnews.imbc.com/replay/2026/nwdesk/",
    "naver_stock": "https://stock.naver.com/",
    "ddanzi_news": "https://www.ddanzi.com/ddanziNews"
}

last_sent_titles = set()

def get_kst_now():
    return datetime.now(timezone(timedelta(hours=9)))

def get_article_summary(url):
    """ê¸°ì‚¬ ì›ë¬¸ì—ì„œ ì²« 3ë¬¸ì¥ì„ ì¶”ì¶œí•˜ì—¬ ìš”ì•½ë³¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"}
    try:
        res = requests.get(url, headers=headers, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ë”´ì§€ì¼ë³´ ê²Œì‹œíŒ ë° ë‰´ìŠ¤ ë³¸ë¬¸ ì˜ì—­ íƒ€ê²ŸíŒ…
        content_area = soup.select_one('#content_1') or soup.select_one('.read_body') or soup.select_one('.view_content')
        
        if content_area:
            # í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ í›„ ì •ì œ
            text = content_area.get_text(separator=' ', strip=True)
            # ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¦¬
            sentences = re.split(r'(?<=[.!?])\s+', text)
            # ì²« 3ë¬¸ì¥ë§Œ ì¶”ì¶œ (ë¹ˆ ë¬¸ì¥ ì œì™¸)
            summary = " ".join([s for s in sentences if len(s) > 5][:3])
            return summary if summary else "ë³¸ë¬¸ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    return "ë¯¸ë¦¬ë³´ê¸°ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜ì´ì§€ì…ë‹ˆë‹¤."

def capture_article_image(url, filename):
    """ë³¸ë¬¸ ì˜ì—­ë§Œ ì •ë°€ íƒ€ê²ŸíŒ…í•˜ì—¬ ìº¡ì²˜"""
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=800,1000") # ì„¸ë¡œí˜• ë·°í¬íŠ¸

    driver = None
    try:
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        driver.get(url)
        time.sleep(3) # ë Œë”ë§ ëŒ€ê¸°
        
        # ë³¸ë¬¸ í•µì‹¬ ìš”ì†Œ ì°¾ê¸°
        try:
            target = driver.find_element(By.CSS_SELECTOR, "#content_1")
            target.screenshot(filename)
        except:
            driver.save_screenshot(filename)
        return filename
    except Exception as e:
        print(f"ìº¡ì²˜ ì‹¤íŒ¨: {e}")
        return None
    finally:
        if driver: driver.quit()

def fetch_data():
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"}
    all_content = []

    # 5. ë”´ì§€ì¼ë³´ ììœ ê²Œì‹œíŒ (ìš”ì•½ ë¡œì§ ì—°ë™)
    try:
        res = requests.get(URLS["ddanzi"], headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        items = soup.select('table.fz_change tbody tr')
        count = 0
        for item in items:
            if count >= 3: break # íš¨ìœ¨ì„ ìœ„í•´ ìƒìœ„ 3ê°œë§Œ
            no_tag = item.select_one('.no')
            if not no_tag or not no_tag.get_text().strip().isdigit(): continue

            title_tag = item.select_one('.title a.link')
            if title_tag:
                link = title_tag['href']
                if not link.startswith('http'): link = "https://www.ddanzi.com" + link
                
                # ìƒì„¸ í˜ì´ì§€ì—ì„œ 3ë¬¸ì¥ ìš”ì•½ ì¶”ì¶œ
                summary = get_article_summary(link)
                
                all_content.append({
                    "source": "ë”´ì§€ê²Œì‹œíŒ", 
                    "title": title_tag.get_text().strip(), 
                    "link": link,
                    "summary": summary,
                    "author": item.select_one('.author').get_text().strip() if item.select_one('.author') else "ìµëª…"
                })
                count += 1
    except Exception as e: print(f"ë”´ì§€ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

    # [ë‹¤ë¥¸ ì†ŒìŠ¤ ìƒëµ - ê¸°ì¡´ ë¡œì§ ìœ ì§€]
    return all_content

async def send_briefing(is_test=False):
    global last_sent_titles
    now = get_kst_now()
    now_str = now.strftime('%Y-%m-%d %H:%M')
    
    data = fetch_data()
    new_items = data[:3] if is_test else [d for d in data if d['link'] not in last_sent_titles]

    if not new_items: return

    bot = telegram.Bot(token=TELEGRAM_TOKEN)

    for item in new_items:
        safe_title = html.escape(item['title'])
        safe_summary = html.escape(item.get('summary', 'ë‚´ìš© ì—†ìŒ'))
        
        # ë©”ì‹œì§€ êµ¬ì„± (ìš”ì•½ë³¸ í¬í•¨)
        report = f"<b>ğŸ”¥ {item['source']}</b>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        report += f"ğŸ“Œ <b>{safe_title}</b>\n\n"
        report += f"ğŸ“ <b>ì£¼ìš” ë‚´ìš© (3ë¬¸ì¥ ìš”ì•½):</b>\n"
        report += f"<blockquote>{safe_summary}</blockquote>\n\n"
        report += f"ğŸ”— <a href='{item['link']}'>ì›ë¬¸ ë³´ê¸°</a>\n"
        report += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"

        temp_img = f"shot_{int(time.time())}.png"
        try:
            img_path = capture_article_image(item['link'], temp_img)
            if img_path and os.path.exists(img_path):
                with open(img_path, 'rb') as photo:
                    await bot.send_photo(chat_id=CHAT_ID, photo=photo, caption=report, parse_mode='HTML')
                os.remove(img_path)
            else:
                await bot.send_message(chat_id=CHAT_ID, text=report, parse_mode='HTML')
            
            last_sent_titles.add(item['link'])
            await asyncio.sleep(1)
        except Exception as e: print(f"ì „ì†¡ ì˜¤ë¥˜: {e}")

def job_wrapper():
    asyncio.run(send_briefing())

if __name__ == "__main__":
    print("ì‹œìŠ¤í…œ ê°€ë™... ë”´ì§€ì¼ë³´ 3ë¬¸ì¥ ìš”ì•½ ëª¨ë“œ í™œì„±í™”")
    asyncio.run(send_briefing(is_test=True))
    schedule.every().hour.at(":00").do(job_wrapper)
    while True:
        schedule.run_pending()
        time.sleep(1)